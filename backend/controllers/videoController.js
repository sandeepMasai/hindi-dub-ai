const Video = require('../models/Video');
const path = require('path');
const fs = require('fs').promises;
const { exec } = require('child_process');
const util = require('util');
const execPromise = util.promisify(exec);

// Create uploads directory if it doesn't exist
const uploadsDir = path.join(__dirname, '../uploads');
const processedDir = path.join(__dirname, '../uploads/processed');

const ensureDirectories = async () => {
  try {
    await fs.mkdir(uploadsDir, { recursive: true });
    await fs.mkdir(processedDir, { recursive: true });
  } catch (error) {
    console.error('Error creating directories:', error);
  }
};

ensureDirectories();

// @desc    Upload video
// @route   POST /api/videos/upload
// @access  Private
const uploadVideo = async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ message: 'No video file uploaded' });
    }

    const { 
      sourceLanguage = 'en', 
      targetLanguage = 'hi',
      duration,
      videoType = 'movie',
      voiceMode = 'natural'
    } = req.body;

    // Validate languages
    if (sourceLanguage === targetLanguage) {
      // Delete uploaded file
      await fs.unlink(req.file.path);
      return res.status(400).json({ 
        message: 'Source and target languages must be different' 
      });
    }

    // Create video record
    const video = await Video.create({
      user: req.user.id,
      originalFileName: req.file.originalname,
      originalFilePath: req.file.path,
      sourceLanguage,
      targetLanguage,
      fileSize: req.file.size,
      duration: duration ? parseInt(duration) * 60 : undefined, // Convert minutes to seconds
      videoType,
      voiceMode,
      status: 'processing',
      progress: 10,
      processingSteps: {
        upload: true,
      },
    });

    // Start processing in background (don't await)
    processVideo(video._id).catch(err => {
      console.error('Video processing error:', err);
    });

    res.status(201).json({
      message: 'Video uploaded successfully',
      video: {
        id: video._id,
        originalFileName: video.originalFileName,
        sourceLanguage: video.sourceLanguage,
        targetLanguage: video.targetLanguage,
        status: video.status,
        progress: video.progress,
      },
    });
  } catch (error) {
    console.error('Upload error:', error);
    res.status(500).json({ message: 'Server error during upload' });
  }
};

// @desc    Process video (background task)
const processVideo = async (videoId) => {
  let video;
  try {
    video = await Video.findById(videoId);
    if (!video) {
      throw new Error('Video not found');
    }

    // Step 1: Extract audio (20% progress)
    await updateProgress(videoId, 20, { audioExtraction: true });
    await extractAudio(video.originalFilePath, videoId);

    // Step 2: Transcribe and translate (40% progress)
    await updateProgress(videoId, 40, { translation: true });
    const translatedText = await translateAudio(videoId, video.sourceLanguage, video.targetLanguage);

    // Step 3: Generate voice (60% progress)
    await updateProgress(videoId, 60, { voiceSynthesis: true });
    const voiceMode = video.voiceMode || 'natural';
    await generateVoice(translatedText, videoId, video.targetLanguage, voiceMode);

    // Step 4: Lip sync (80% progress)
    await updateProgress(videoId, 80, { lipSync: true });
    await applyLipSync(video.originalFilePath, videoId);

    // Step 5: Render final video (90% progress)
    await updateProgress(videoId, 90, { rendering: true });
    const outputPath = await renderFinalVideo(video.originalFilePath, videoId);

    // Complete (100% progress)
    await Video.findByIdAndUpdate(videoId, {
      status: 'completed',
      progress: 100,
      processedFilePath: outputPath,
    });

    console.log(`Video ${videoId} processed successfully`);
  } catch (error) {
    console.error(`Error processing video ${videoId}:`, error);
    if (video) {
      await Video.findByIdAndUpdate(videoId, {
        status: 'failed',
        errorMessage: error.message,
      });
    }
  }
};

// Helper: Update progress
const updateProgress = async (videoId, progress, steps = {}) => {
  const updateData = { progress };
  if (Object.keys(steps).length > 0) {
    updateData.processingSteps = steps;
  }
  await Video.findByIdAndUpdate(videoId, updateData);
};

// Helper: Extract audio from video
const extractAudio = async (videoPath, videoId) => {
  const audioPath = path.join(uploadsDir, `${videoId}_audio.wav`);
  const mp3Path = path.join(uploadsDir, `${videoId}_audio.mp3`);
  
  try {
    console.log('üéµ Extracting audio from video...');
    
    // First, check if video has audio stream
    const checkCommand = `ffprobe -v error -select_streams a:0 -show_entries stream=codec_type -of default=noprint_wrappers=1:nokey=1 "${videoPath}"`;
    
    try {
      const { stdout } = await execPromise(checkCommand);
      if (!stdout.trim()) {
        console.warn('‚ö†Ô∏è Video has no audio stream');
        throw new Error('No audio stream found');
      }
    } catch (probeError) {
      console.warn('‚ö†Ô∏è Video has no audio stream');
      throw new Error('No audio stream found');
    }
    
    // Extract audio to MP3 first (more compatible)
    const extractCommand = `ffmpeg -i "${videoPath}" -vn -acodec libmp3lame -ar 16000 -ac 1 -b:a 128k "${mp3Path}" -y`;
    await execPromise(extractCommand);
    console.log('‚úÖ Audio extracted to MP3');
    
    // Convert MP3 to WAV for better compatibility with Whisper
    const convertCommand = `ffmpeg -i "${mp3Path}" -acodec pcm_s16le -ar 16000 -ac 1 "${audioPath}" -y`;
    await execPromise(convertCommand);
    console.log('‚úÖ Audio converted to WAV');
    
    // Verify file exists and has content
    const stats = await fs.stat(audioPath);
    if (stats.size < 1000) {
      throw new Error('Audio file too small');
    }
    
    console.log(`‚úÖ Audio extracted successfully (${(stats.size / 1024).toFixed(2)} KB)`);
    return audioPath;
    
  } catch (error) {
    console.error('‚ùå Audio extraction failed:', error.message);
    console.log('‚ö†Ô∏è Video may not have audio or audio extraction failed');
    console.log('‚ö†Ô∏è Will use sample text for dubbing');
    
    // Create a minimal valid WAV file for fallback
    const wavHeader = Buffer.alloc(44);
    wavHeader.write('RIFF', 0);
    wavHeader.writeUInt32LE(36, 4);
    wavHeader.write('WAVE', 8);
    wavHeader.write('fmt ', 12);
    wavHeader.writeUInt32LE(16, 16);
    wavHeader.writeUInt16LE(1, 20);
    wavHeader.writeUInt16LE(1, 22);
    wavHeader.writeUInt32LE(16000, 24);
    wavHeader.writeUInt32LE(32000, 28);
    wavHeader.writeUInt16LE(2, 32);
    wavHeader.writeUInt16LE(16, 34);
    wavHeader.write('data', 36);
    wavHeader.writeUInt32LE(0, 40);
    
    await fs.writeFile(audioPath, wavHeader);
    return audioPath;
  }
};

// Helper: Translate audio
const translateAudio = async (videoId, sourceLang, targetLang) => {
  const audioPath = path.join(uploadsDir, `${videoId}_audio.wav`);
  const mp3Path = path.join(uploadsDir, `${videoId}_audio.mp3`);
  const axios = require('axios');
  const FormData = require('form-data');
  
  try {
    // Check if audio file exists and has content
    const stats = await fs.stat(audioPath);
    const hasRealAudio = stats.size > 1000; // More than just WAV header
    
    if (!hasRealAudio) {
      console.log('‚ö†Ô∏è No real audio in video, using sample text');
      throw new Error('No audio content');
    }
    
    // Step 1: Transcribe audio using OpenAI Whisper
    console.log('üìù Transcribing audio with Whisper...');
    const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
    
    if (OPENAI_API_KEY && OPENAI_API_KEY !== 'your_openai_api_key_here') {
      try {
        // Use MP3 if available (smaller file size)
        const audioFileToUse = await fs.access(mp3Path).then(() => mp3Path).catch(() => audioPath);
        const audioBuffer = await fs.readFile(audioFileToUse);
        
        console.log(`üì§ Uploading audio file (${(audioBuffer.length / 1024).toFixed(2)} KB) to Whisper...`);
        
        const formData = new FormData();
        formData.append('file', audioBuffer, {
          filename: path.basename(audioFileToUse),
          contentType: audioFileToUse.endsWith('.mp3') ? 'audio/mpeg' : 'audio/wav'
        });
        formData.append('model', 'whisper-1');
        formData.append('language', sourceLang);
        formData.append('response_format', 'json');
        
        const transcribeResponse = await axios.post(
          'https://api.openai.com/v1/audio/transcriptions',
          formData,
          {
            headers: {
              ...formData.getHeaders(),
              'Authorization': `Bearer ${OPENAI_API_KEY}`
            },
            maxContentLength: Infinity,
            maxBodyLength: Infinity,
            timeout: 60000
          }
        );
        
        const transcribedText = transcribeResponse.data.text;
        
        if (!transcribedText || transcribedText.trim().length === 0) {
          throw new Error('Empty transcription result');
        }
        
        console.log('‚úÖ Transcription successful!');
        console.log(`üìù Original text (${sourceLang}): ${transcribedText.substring(0, 150)}...`);
        
        // Step 2: Translate text
        console.log(`üåê Translating from ${sourceLang} to ${targetLang}...`);
        const GOOGLE_TRANSLATE_KEY = process.env.GOOGLE_TRANSLATE_API_KEY;
        
        // Try Google Translate first
        if (GOOGLE_TRANSLATE_KEY && GOOGLE_TRANSLATE_KEY !== 'your_google_translate_api_key_here') {
          try {
            const translateResponse = await axios.post(
              `https://translation.googleapis.com/language/translate/v2?key=${GOOGLE_TRANSLATE_KEY}`,
              {
                q: transcribedText,
                source: sourceLang,
                target: targetLang,
                format: 'text'
              }
            );
            
            const translatedText = translateResponse.data.data.translations[0].translatedText;
            console.log('‚úÖ Google Translation successful!');
            console.log(`üìù Translated text (${targetLang}): ${translatedText.substring(0, 150)}...`);
            return translatedText;
          } catch (googleError) {
            console.warn('‚ö†Ô∏è Google Translate failed:', googleError.message);
          }
        }
        
        // Fallback: Use free MyMemory API
        console.log('üîÑ Using free MyMemory translation API...');
        try {
          const translateResponse = await axios.get(
            `https://api.mymemory.translated.net/get?q=${encodeURIComponent(transcribedText)}&langpair=${sourceLang}|${targetLang}`,
            { timeout: 30000 }
          );
          
          if (translateResponse.data.responseData && translateResponse.data.responseData.translatedText) {
            const translatedText = translateResponse.data.responseData.translatedText;
            console.log('‚úÖ Free translation successful!');
            console.log(`üìù Translated text (${targetLang}): ${translatedText.substring(0, 150)}...`);
            return translatedText;
          }
        } catch (freeApiError) {
          console.warn('‚ö†Ô∏è Free translation API failed:', freeApiError.message);
        }
        
        // If translation fails but we have transcription, return it
        console.log('‚ö†Ô∏è Translation failed, using original transcribed text');
        return transcribedText;
        
      } catch (apiError) {
        console.error('‚ùå Whisper API failed:', apiError.message);
        if (apiError.response) {
          console.error('API Status:', apiError.response.status);
          console.error('API Error:', apiError.response.data);
        }
      }
    } else {
      console.log('‚ö†Ô∏è No OpenAI API key configured');
    }
    
    // Fallback: Use sample text
    console.log('‚ö†Ô∏è Using sample text for dubbing...');
    await new Promise(resolve => setTimeout(resolve, 2000));
    
    const sampleTexts = {
      'hi': '‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Ø‡§π ‡§è‡§ï ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§π‡•à‡•§ ‡§π‡§Æ ‡§á‡§∏ ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§ï‡•ã ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§°‡§¨ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§ ‡§Ø‡§π ‡§è‡§ï ‡§∂‡§æ‡§®‡§¶‡§æ‡§∞ ‡§§‡§ï‡§®‡•Ä‡§ï ‡§π‡•à ‡§ú‡•ã ‡§Ü‡§™‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú ‡§ï‡•ã ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤ ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡•§',
      'es': 'Hola! Este es un video de prueba. Estamos doblando este video al espa√±ol. Esta es una tecnolog√≠a incre√≠ble que puede convertir tu voz a cualquier idioma.',
      'fr': 'Bonjour! Ceci est une vid√©o de test. Nous doublons cette vid√©o en fran√ßais. C\'est une technologie incroyable qui peut convertir votre voix dans n\'importe quelle langue.',
      'de': 'Hallo! Dies ist ein Testvideo. Wir synchronisieren dieses Video auf Deutsch. Dies ist eine erstaunliche Technologie, die Ihre Stimme in jede Sprache umwandeln kann.',
      'ja': '„Åì„Çì„Å´„Å°„ÅØÔºÅ„Åì„Çå„ÅØ„ÉÜ„Çπ„Éà„Éì„Éá„Ç™„Åß„Åô„ÄÇ„Åì„ÅÆ„Éì„Éá„Ç™„ÇíÊó•Êú¨Ë™û„Å´Âêπ„ÅçÊõø„Åà„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åì„Çå„ÅØ„ÅÇ„Å™„Åü„ÅÆÂ£∞„Çí„Å©„Çì„Å™Ë®ÄË™û„Å´„ÇÇÂ§âÊèõ„Åß„Åç„ÇãÁ¥†Êô¥„Çâ„Åó„ÅÑÊäÄË°ì„Åß„Åô„ÄÇ',
      'zh': '‰Ω†Â•ΩÔºÅËøôÊòØ‰∏Ä‰∏™ÊµãËØïËßÜÈ¢ë„ÄÇÊàë‰ª¨Ê≠£Âú®Â∞ÜÊ≠§ËßÜÈ¢ëÈÖçÈü≥‰∏∫‰∏≠Êñá„ÄÇËøôÊòØ‰∏ÄÈ°π‰∫Ü‰∏çËµ∑ÁöÑÊäÄÊúØÔºåÂèØ‰ª•Â∞ÜÊÇ®ÁöÑÂ£∞Èü≥ËΩ¨Êç¢‰∏∫‰ªª‰ΩïËØ≠Ë®Ä„ÄÇ',
      'en': 'Hello! This is a test video. We are dubbing this video in English. This is an amazing technology that can convert your voice to any language.'
    };
    
    return sampleTexts[targetLang] || sampleTexts['en'];
    
  } catch (error) {
    console.error('‚ùå Translation process error:', error.message);
    
    // Return sample text as ultimate fallback
    const sampleTexts = {
      'hi': '‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Ø‡§π ‡§è‡§ï ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§π‡•à‡•§ ‡§π‡§Æ ‡§á‡§∏ ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§ï‡•ã ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§°‡§¨ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§',
      'en': 'Hello! This is a test video. We are dubbing this video.'
    };
    
    return sampleTexts[targetLang] || sampleTexts['en'];
  }
};

// Helper: Generate voice using ElevenLabs TTS API
const generateVoice = async (text, videoId, targetLang, voiceMode = 'natural') => {
  const ELEVENLABS_API_KEY = process.env.ELEVENLABS_API_KEY || 'sk_909dce2aa52a5d2b106122e74332dcf7e79bf3346e48afd3';
  const voicePath = path.join(uploadsDir, `${videoId}_voice.mp3`);
  const axios = require('axios');
  
  try {
    // ElevenLabs voice IDs - Using multilingual voices
    const voiceIds = {
      'en': '21m00Tcm4TlvDq8ikWAM', // Rachel (English)
      'hi': 'pNInz6obpgDQGcFmaJgB', // Adam (Multilingual - works for Hindi)
      'es': 'EXAVITQu4vr4xnSDxMaL', // Bella (Spanish)
      'fr': 'ErXwobaYiN019PkySvjV', // Antoni (French)
      'de': 'VR6AewLTigWG4xSOukaG', // Arnold (German)
      'pt': 'pqHfZKP75CvOlQylNhV4', // Bill (Portuguese)
      'zh': 'yoZ06aMxZJJ28mfd3POQ', // Charlotte (Chinese)
      'ja': 'bVMeCyTHy58xNoL34h3p', // Clyde (Japanese)
      'ko': 'iP95p4xoKVk53GoZ742B', // Dave (Korean)
      'ar': 'pNInz6obpgDQGcFmaJgB', // Adam (Arabic)
      'bn': 'pNInz6obpgDQGcFmaJgB', // Adam (Bengali)
      'ta': 'pNInz6obpgDQGcFmaJgB', // Adam (Tamil)
      'te': 'pNInz6obpgDQGcFmaJgB', // Adam (Telugu)
    };
    
    const voiceId = voiceIds[targetLang] || voiceIds['en'];
    
    // Voice settings based on mode
    const voiceSettings = {
      'natural': {
        stability: 0.5,
        similarity_boost: 0.75,
        style: 0.0,
        use_speaker_boost: true
      },
      'expressive': {
        stability: 0.3,
        similarity_boost: 0.85,
        style: 0.5,
        use_speaker_boost: true
      },
      'calm': {
        stability: 0.7,
        similarity_boost: 0.6,
        style: 0.0,
        use_speaker_boost: false
      },
      'energetic': {
        stability: 0.4,
        similarity_boost: 0.8,
        style: 0.6,
        use_speaker_boost: true
      }
    };
    
    const settings = voiceSettings[voiceMode] || voiceSettings['natural'];
    
    console.log(`Generating voice with ElevenLabs`);
    console.log(`Language: ${targetLang}, Mode: ${voiceMode}`);
    console.log(`Text to speak: ${text.substring(0, 100)}...`);
    
    // Call ElevenLabs API
    const response = await axios.post(
      `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`,
      {
        text: text,
        model_id: 'eleven_multilingual_v2', // Supports multiple languages including Hindi
        voice_settings: settings
      },
      {
        headers: {
          'Accept': 'audio/mpeg',
          'Content-Type': 'application/json',
          'xi-api-key': ELEVENLABS_API_KEY
        },
        responseType: 'arraybuffer',
        timeout: 60000 // 60 second timeout
      }
    );
    
    // Save the audio file
    await fs.writeFile(voicePath, response.data);
    console.log('‚úÖ Voice generated successfully with ElevenLabs');
    console.log(`Audio file size: ${(response.data.length / 1024).toFixed(2)} KB`);
    
    // Convert MP3 to WAV if needed (for compatibility with Wav2Lip)
    const wavPath = path.join(uploadsDir, `${videoId}_voice.wav`);
    try {
      // Use FFmpeg to convert MP3 to WAV
      await execPromise(`ffmpeg -i "${voicePath}" -acodec pcm_s16le -ar 16000 "${wavPath}"`);
      console.log('‚úÖ Converted MP3 to WAV format');
      return wavPath;
    } catch (conversionError) {
      console.warn('FFmpeg conversion failed, using MP3:', conversionError.message);
      return voicePath;
    }
    
  } catch (error) {
    console.error('‚ùå ElevenLabs TTS error:', error.response?.data || error.message);
    
    if (error.response) {
      console.error('API Response Status:', error.response.status);
      console.error('API Response Data:', error.response.data);
    }
    
    // Fallback: simulate voice generation
    console.log('‚ö†Ô∏è Falling back to simulated voice generation');
    await new Promise(resolve => setTimeout(resolve, 3000));
    
    // Create a dummy file for testing
    const wavPath = path.join(uploadsDir, `${videoId}_voice.wav`);
    await fs.writeFile(wavPath, Buffer.from('dummy audio data'));
    
    return wavPath;
  }
};

// Helper: Apply lip sync using Wav2Lip API
const applyLipSync = async (videoPath, videoId) => {
  const WAV2LIP_API_KEY = 'sk-Kc5-RxKFRtqJ8krsHMIPKw.Qoqz4SbQRSze-3gjsN8X_FPtlRbboEaw';
  const voicePath = path.join(uploadsDir, `${videoId}_voice.wav`);
  const outputPath = path.join(processedDir, `${videoId}_lipsynced.mp4`);
  
  try {
    // Wav2Lip API integration
    // Note: Replace with actual Wav2Lip API endpoint when available
    const FormData = require('form-data');
    const axios = require('axios');
    
    const formData = new FormData();
    formData.append('video', await fs.readFile(videoPath), {
      filename: path.basename(videoPath),
      contentType: 'video/mp4'
    });
    formData.append('audio', await fs.readFile(voicePath), {
      filename: path.basename(voicePath),
      contentType: 'audio/wav'
    });
    
    // Example API call (adjust endpoint as needed)
    // const response = await axios.post('https://api.wav2lip.com/v1/sync', formData, {
    //   headers: {
    //     ...formData.getHeaders(),
    //     'Authorization': `Bearer ${WAV2LIP_API_KEY}`
    //   },
    //   maxContentLength: Infinity,
    //   maxBodyLength: Infinity
    // });
    
    // For now, simulate the process
    console.log('Using Wav2Lip API Key for lip sync...');
    await new Promise(resolve => setTimeout(resolve, 2000));
    
    // In production:
    // 1. Upload video and audio to Wav2Lip API
    // 2. Wait for processing
    // 3. Download the lip-synced video
    // 4. Save to outputPath
    
    return outputPath;
  } catch (error) {
    console.error('Lip sync error:', error);
    throw new Error('Lip sync failed');
  }
};

// Helper: Render final video
const renderFinalVideo = async (originalPath, videoId) => {
  const outputPath = path.join(processedDir, `${videoId}_dubbed.mp4`);
  const voicePath = path.join(uploadsDir, `${videoId}_voice.wav`);
  
  try {
    // Check if voice file exists
    try {
      await fs.access(voicePath);
    } catch {
      // If voice file doesn't exist, create a dummy one
      await fs.writeFile(voicePath, Buffer.from('dummy audio'));
    }
    
    // Try to use FFmpeg to combine video and audio
    try {
      const command = `ffmpeg -i "${originalPath}" -i "${voicePath}" -c:v copy -c:a aac -map 0:v:0 -map 1:a:0 -shortest "${outputPath}"`;
      await execPromise(command);
      console.log('Video rendered successfully with FFmpeg');
    } catch (ffmpegError) {
      console.warn('FFmpeg rendering failed, copying original file:', ffmpegError.message);
      // Fallback: copy the original file as the output
      await fs.copyFile(originalPath, outputPath);
      console.log('Copied original file as output');
    }
    
    // Verify output file exists
    await fs.access(outputPath);
    console.log(`Output file created at: ${outputPath}`);
    
    return outputPath;
  } catch (error) {
    console.error('Render final video error:', error);
    // Last resort: copy original file
    try {
      await fs.copyFile(originalPath, outputPath);
      return outputPath;
    } catch (copyError) {
      throw new Error(`Failed to create output file: ${copyError.message}`);
    }
  }
};

// @desc    Get video status
// @route   GET /api/videos/:id
// @access  Private
const getVideoStatus = async (req, res) => {
  try {
    const video = await Video.findById(req.params.id);

    if (!video) {
      return res.status(404).json({ message: 'Video not found' });
    }

    // Check if user owns this video
    if (video.user.toString() !== req.user.id) {
      return res.status(403).json({ message: 'Not authorized' });
    }

    res.json({
      id: video._id,
      originalFileName: video.originalFileName,
      sourceLanguage: video.sourceLanguage,
      targetLanguage: video.targetLanguage,
      status: video.status,
      progress: video.progress,
      processingSteps: video.processingSteps,
      errorMessage: video.errorMessage,
      createdAt: video.createdAt,
      updatedAt: video.updatedAt,
    });
  } catch (error) {
    console.error('Get video status error:', error);
    res.status(500).json({ message: 'Server error' });
  }
};

// @desc    Get all user videos
// @route   GET /api/videos
// @access  Private
const getUserVideos = async (req, res) => {
  try {
    const videos = await Video.find({ user: req.user.id })
      .sort({ createdAt: -1 })
      .select('-originalFilePath -processedFilePath');

    res.json(videos);
  } catch (error) {
    console.error('Get user videos error:', error);
    res.status(500).json({ message: 'Server error' });
  }
};

// @desc    Download processed video
// @route   GET /api/videos/:id/download
// @access  Private
const downloadVideo = async (req, res) => {
  try {
    const video = await Video.findById(req.params.id);

    if (!video) {
      return res.status(404).json({ message: 'Video not found' });
    }

    // Check if user owns this video
    if (video.user.toString() !== req.user.id) {
      return res.status(403).json({ message: 'Not authorized' });
    }

    if (video.status !== 'completed') {
      return res.status(400).json({ message: 'Video processing not completed yet. Please wait.' });
    }

    if (!video.processedFilePath) {
      return res.status(404).json({ message: 'Processed video file path not found' });
    }

    // Check if file exists
    try {
      await fs.access(video.processedFilePath);
    } catch (fileError) {
      console.error('Processed file not found:', video.processedFilePath);
      
      // Try to use original file as fallback
      if (video.originalFilePath) {
        try {
          await fs.access(video.originalFilePath);
          console.log('Using original file as fallback');
          return res.download(video.originalFilePath, `original_${video.originalFileName}`);
        } catch {
          return res.status(404).json({ 
            message: 'Processed video file not found on server',
            details: 'The file may have been deleted or moved'
          });
        }
      }
      
      return res.status(404).json({ 
        message: 'Video file not found on server',
        details: 'Please try processing the video again'
      });
    }

    // Send file
    console.log(`Sending file: ${video.processedFilePath}`);
    res.download(video.processedFilePath, `dubbed_${video.originalFileName}`, (err) => {
      if (err) {
        console.error('Error sending file:', err);
        if (!res.headersSent) {
          res.status(500).json({ message: 'Error downloading file' });
        }
      }
    });
  } catch (error) {
    console.error('Download video error:', error);
    res.status(500).json({ 
      message: 'Server error',
      error: error.message 
    });
  }
};

// @desc    Delete video
// @route   DELETE /api/videos/:id
// @access  Private
const deleteVideo = async (req, res) => {
  try {
    const video = await Video.findById(req.params.id);

    if (!video) {
      return res.status(404).json({ message: 'Video not found' });
    }

    // Check if user owns this video
    if (video.user.toString() !== req.user.id) {
      return res.status(403).json({ message: 'Not authorized' });
    }

    // Delete files
    try {
      if (video.originalFilePath) {
        await fs.unlink(video.originalFilePath);
      }
      if (video.processedFilePath) {
        await fs.unlink(video.processedFilePath);
      }
      // Delete audio files
      const audioPath = path.join(uploadsDir, `${video._id}_audio.wav`);
      const voicePath = path.join(uploadsDir, `${video._id}_voice.wav`);
      await fs.unlink(audioPath).catch(() => {});
      await fs.unlink(voicePath).catch(() => {});
    } catch (fileError) {
      console.error('Error deleting files:', fileError);
    }

    await video.deleteOne();

    res.json({ message: 'Video deleted successfully' });
  } catch (error) {
    console.error('Delete video error:', error);
    res.status(500).json({ message: 'Server error' });
  }
};

module.exports = {
  uploadVideo,
  getVideoStatus,
  getUserVideos,
  downloadVideo,
  deleteVideo,
};
